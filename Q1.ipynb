{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9c878e8-29d6-4edb-ae36-dcbfba281639",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6afadac-211d-4e81-9995-f29a68be4ff9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import tempfile\n",
    "\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, explode, split, sum as spark_sum, countDistinct, collect_list, to_timestamp, lit, round\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType \n",
    "\n",
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "827f3ca3-e5c4-4001-8e4c-19a97eca5be1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/30 08:37:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[key: string, value: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.config('spark.ui.port', 64053).appName(\"Ass4_Q1\").getOrCreate()\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb72d4ab-360b-467b-a38f-10f32e4ec08a",
   "metadata": {},
   "source": [
    "## (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "504c0bc5-6652-4bc9-94b0-21c9255630ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_data = spark.read.format(\"csv\")\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .option(\"inferSchema\", \"true\")\\\n",
    "  .load(\"./data/departuredelays.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "848aa91e-4987-4126-ba0a-339ff0e03d24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------+------+-----------+\n",
      "|   date|delay|distance|origin|destination|\n",
      "+-------+-----+--------+------+-----------+\n",
      "|1011245|    6|     602|   ABE|        ATL|\n",
      "|1020600|   -8|     369|   ABE|        DTW|\n",
      "|1021245|   -2|     602|   ABE|        ATL|\n",
      "|1020605|   -4|     602|   ABE|        ATL|\n",
      "|1031245|   -4|     602|   ABE|        ATL|\n",
      "|1030605|    0|     602|   ABE|        ATL|\n",
      "|1041243|   10|     602|   ABE|        ATL|\n",
      "|1040605|   28|     602|   ABE|        ATL|\n",
      "|1051245|   88|     602|   ABE|        ATL|\n",
      "|1050605|    9|     602|   ABE|        ATL|\n",
      "|1061215|   -6|     602|   ABE|        ATL|\n",
      "|1061725|   69|     602|   ABE|        ATL|\n",
      "|1061230|    0|     369|   ABE|        DTW|\n",
      "|1060625|   -3|     602|   ABE|        ATL|\n",
      "|1070600|    0|     369|   ABE|        DTW|\n",
      "|1071725|    0|     602|   ABE|        ATL|\n",
      "|1071230|    0|     369|   ABE|        DTW|\n",
      "|1070625|    0|     602|   ABE|        ATL|\n",
      "|1071219|    0|     569|   ABE|        ORD|\n",
      "|1080600|    0|     369|   ABE|        DTW|\n",
      "+-------+-----+--------+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596c5cdc-50d3-4659-bc7f-0a7d25f14f15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python sp",
   "language": "python",
   "name": "sp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
